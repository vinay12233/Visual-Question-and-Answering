{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4S4QWQ6eaNd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f6f137ce-b677-497d-de51-2fffc94709c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "enter the question : how many members in the image\n",
            "Q: how many members in the image A: three\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "enter the question : how many males\n",
            "Q: how many males A: 1\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "enter the question : how many females\n",
            "Q: how many females A: 2\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
        "from PIL import Image\n",
        "\n",
        "# Load the processor and model\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "\n",
        "# Function to predict objects in an image\n",
        "def predict_object(image_path, question):\n",
        "    # Load and process the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Process inputs\n",
        "    inputs = processor(image, question, return_tensors=\"pt\")\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(**inputs)\n",
        "        answer = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/portrait-family-reading-book-together-sitting-sofa_23-2148045599.jpg\"\n",
        "\n",
        "for i in range (0,5):\n",
        "  question = (input(\"\\n\\nenter the question : \"))\n",
        "  answer = predict_object(image_path, question)\n",
        "  print(f\"Q: {question} A: {answer}\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}